{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNQIyfTU3nAGgFEWmn2CnQ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natsakh/IAD/blob/main/Pr_7/7_7_HF_Fine_tuning_DistilBERT_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install transformers"
      ],
      "metadata": {
        "id": "aThxDnkyC6jm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
      ],
      "metadata": {
        "id": "05l3x253Syzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfafe1ad-faf7-4fca-94e7-d41d45acd61d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtywNdrP7Eqg"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "raw_datasets = load_dataset(\"imdb\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мінімальний набір для fine-tuning через Trainer\n",
        "\n",
        "Для тренування DistilBERT потрібні:\n",
        "\n",
        "✔ AutoTokenizer - Щоб токенізувати текст\n",
        "\n",
        "✔ AutoModelForSequenceClassification - Модель з classifier-головою\n",
        "\n",
        "✔ DataCollatorWithPadding - Автоматичний батч-паддінг\n",
        "\n",
        "✔ TrainingArguments - Налаштування тренування\n",
        "\n",
        "✔ Trainer - Запуск навчання"
      ],
      "metadata": {
        "id": "cYeslUeZSgTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")"
      ],
      "metadata": {
        "id": "6s_po3HDTJQG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DistilBERT для донавчання на IMDB\n",
        "\n",
        "Тепер беремо модель: distilbert-base-uncased (без готової “голови” на SST-2), і будемо її донавчати на 2 класи IMDB."
      ],
      "metadata": {
        "id": "zzboyIsT7nzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Токенайзер + модель\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=2,          # IMDB: 0 = negative, 1 = positive\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHqBAmLG7egI",
        "outputId": "8e584d87-bb2f-4e09-da1c-539a2b5bbce5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Функція токенізації\n",
        "def tokenize_batch(batch):\n",
        "    return tokenizer(\n",
        "        batch[\"text\"],\n",
        "        padding=False,\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "    )\n"
      ],
      "metadata": {
        "id": "EQcVB-JH78Qu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets.utils.logging import disable_progress_bar\n",
        "disable_progress_bar()\n",
        "\n",
        "# Напр., по 4000 прикладів на train / test\n",
        "small_train = raw_datasets[\"train\"].shuffle(seed=42).select(range(4000))\n",
        "small_test  = raw_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n",
        "\n",
        "tokenized_train = small_train.map(tokenize_batch, batched=True)\n",
        "tokenized_test  = small_test.map(tokenize_batch,  batched=True)\n"
      ],
      "metadata": {
        "id": "iGHU9XeE8X_P"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "id": "mVBJI11z8oc5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc}"
      ],
      "metadata": {
        "id": "ZEKsGB3680qx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size= 16\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"distilbert-imdb\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_UBOQMh84ur",
        "outputId": "ac8c10f1-d8fd-434e-85ad-e0412a73e173",
        "collapsed": true
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdcEeVci-XJe",
        "outputId": "a1bf2a05-5557-4245-fe12-7e06d546d4a9",
        "collapsed": true
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3908350211.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "C8c7YS5--aXm",
        "outputId": "59d2af96-932f-4581-a054-bfafd7a16005"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 03:26, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.345100</td>\n",
              "      <td>0.283168</td>\n",
              "      <td>0.870000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.155100</td>\n",
              "      <td>0.299891</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=500, training_loss=0.2985546636581421, metrics={'train_runtime': 209.0757, 'train_samples_per_second': 38.264, 'train_steps_per_second': 2.391, 'total_flos': 529869594624000.0, 'train_loss': 0.2985546636581421, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}