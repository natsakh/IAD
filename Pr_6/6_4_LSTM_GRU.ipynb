{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhdXlI4KpWIkQIwSAwozFJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natsakh/IAD/blob/main/Pr_6/6_4_LSTM_GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5VNexrAlGNch"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# synthetic data\n",
        "x = torch.rand(32, 50, 10) # batch, time_steps, features"
      ],
      "metadata": {
        "id": "ntSDawxxuCJ2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM\n",
        "input_size: dimensionality of the input features\n",
        "\n",
        "hidden_size: dimensionality of the hidden size\n",
        "\n",
        "batch_first: if True - input/output shape is [batch, seq_len, featues] instead of [seq_len, batch, featues]  \n",
        "\n",
        "The sequence length is not passed to nn.LSTM; it is inferred from the input tensor shape\n"
      ],
      "metadata": {
        "id": "iUUlryQtrQmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = nn.LSTM(10, 20, batch_first = True)\n",
        "output, (h_n, c_n) = lstm(x)\n",
        "# output = приховані стани для кожного кроку [B, T, H]\n",
        "# h_n = останній hidden\n",
        "# c_n = останній cell"
      ],
      "metadata": {
        "id": "nnJR-sYLGdgH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMONLUwtG4Mo",
        "outputId": "b01fe143-f502-455f-f3c9-4709a6ba4089"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 50, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(h_n.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZYXmWuVHw9_",
        "outputId": "4f39d3b8-07e3-40a4-efe0-376e285ac278"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 32, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_last = output[:, -1, :] # last  time step output"
      ],
      "metadata": {
        "id": "TBVx7L8iI0SW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_last.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LluP87Y_JAZH",
        "outputId": "bd84f358-995c-4ee5-e8e8-87ce42583f07"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bidirectional\n",
        "lstm = nn.LSTM(input_size=10, hidden_size=20, bidirectional=True, batch_first=True)\n",
        "output, (h_n, c_n) = lstm(x)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpDnMI4uJ-XP",
        "outputId": "bba907a8-cd8e-4b0e-da12-e3d12f52dd65"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 50, 40])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(h_n.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3ASpg6PxJxl",
        "outputId": "27aaa3ef-6263-461a-f950-646aa4cee01b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 32, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 LSTM layers\n",
        "lstm = nn.LSTM(input_size=10, hidden_size=20, num_layers=3, batch_first=True)\n",
        "output, (h_n, c_n) = lstm(x)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLx4hli7O3ta",
        "outputId": "beed690e-5e3f-4582-f974-0f2f21093fd2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 50, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(h_n.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AjUJL32xUbK",
        "outputId": "8fc44410-0b88-4924-d136-b72056008101"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 32, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_last = output[:, -1, :]\n",
        "print(y_last.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QLbC00ePHbI",
        "outputId": "e4152f1f-7f84-4395-83ac-0d96fae6d1f8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GRU"
      ],
      "metadata": {
        "id": "A7zzkj9yxfde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gru = nn.GRU(input_size=10, hidden_size=20, num_layers=1, batch_first=True)\n",
        "\n",
        "x = torch.randn(32, 50, 10)       # [batch, time_steps, features]\n",
        "output, h_n = gru(x)\n",
        "\n",
        "print(output.shape)  # torch.Size([32, 50, 20]) - all time steps\n",
        "print(h_n.shape)     # torch.Size([1, 32, 20])  - last hidden state\n",
        "\n",
        "h_last = output[:, -1, :]         # last time step → like return_sequences=False\n",
        "print(h_last.shape)  # torch.Size([32, 20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRE2QtccZZG1",
        "outputId": "13a79c78-160b-4dd4-e79d-c21b40aaeb53"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 50, 20])\n",
            "torch.Size([1, 32, 20])\n",
            "torch.Size([32, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embedding Layer"
      ],
      "metadata": {
        "id": "ncRHxjOfx_KF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: vocabulary of 6 words, 2-dimensional embeddings\n",
        "embedding = nn.Embedding(num_embeddings=6, embedding_dim=2)\n",
        "\n",
        "# input: sequence of word indices (batch of 2 sentences, each length 3)\n",
        "x = torch.tensor([[0, 1, 2],\n",
        "                  [3, 4, 5]])       # [batch, seq_len]\n",
        "\n",
        "out = embedding(x)\n",
        "\n",
        "print(out.shape)  # torch.Size([2, 3, 2]) → [batch, seq_len, embedding_dim]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7m9Uns7Td6Hm",
        "outputId": "d5b65f7e-93b1-47bf-f1d9-8e1fd9de1b3d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(out[0].shape)# torch.Size([3, 2]) embeddings for the first sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Pn7UUjNyJ7L",
        "outputId": "3de9b1f1-6635-4fe9-cd34-6a35a93502da"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(out[0][0], out[0][1], out[0][2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmAlH6DDyK4F",
        "outputId": "11f034b6-c718-4253-82db-18dedad2644e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.4904, -0.4899], grad_fn=<SelectBackward0>) tensor([-0.9374,  0.5820], grad_fn=<SelectBackward0>) tensor([-0.1159,  0.6641], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    }
  ]
}